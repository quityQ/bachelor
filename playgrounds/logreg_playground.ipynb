{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression, using scikit-learn and statsmodels (based on introduction to statistical learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from ISLP.models import summarize\n",
    "from ISLP import confusion_table\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "large = pd.read_csv('../datasets/full_cleaned_dataset.csv')\n",
    "small = pd.read_csv('../datasets/1std_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnesacary columns (z_score column, and index columns, and year))\n",
    "small.drop(columns=['z_score', 'year'], inplace=True)\n",
    "large.drop(columns=['Unnamed: 0', 'year'], inplace=True)\n",
    "\n",
    "#drop any non-numeric colums from both datasets\n",
    "#getting lists of numeric columns\n",
    "numeric_columns = large.select_dtypes(include=np.number).columns\n",
    "\n",
    "#dropping non-numeric columns from large and small datasets\n",
    "large = large[numeric_columns]\n",
    "small = small[numeric_columns]\n",
    "\n",
    "#move the target (distressed) out of the dataset\n",
    "large_target = large.pop('distressed')\n",
    "small_target = small.pop('distressed')\n",
    "\n",
    "#turn dfs in numpy arrays\n",
    "nplarge = large.to_numpy()\n",
    "npsmall = small.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                  667\n",
      "Model:                            GLM   Df Residuals:                      567\n",
      "Model Family:                Binomial   Df Model:                           99\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                   3.6244e-09\n",
      "Time:                        10:27:30   Pearson chi2:                 1.81e-09\n",
      "No. Iterations:                    30   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           326.1650   3.81e+06   8.57e-05      1.000   -7.46e+06    7.46e+06\n",
      "x2            63.7473    3.5e+05      0.000      1.000   -6.86e+05    6.86e+05\n",
      "x3          -903.6926   2.31e+06     -0.000      1.000   -4.52e+06    4.52e+06\n",
      "x4            86.0515   7.52e+05      0.000      1.000   -1.47e+06    1.47e+06\n",
      "x5           371.6054    5.6e+06   6.63e-05      1.000    -1.1e+07     1.1e+07\n",
      "x6            79.0391   1.07e+06   7.42e-05      1.000   -2.09e+06    2.09e+06\n",
      "x7           635.6358   2.89e+06      0.000      1.000   -5.67e+06    5.67e+06\n",
      "x8           -18.1822   7.18e+05  -2.53e-05      1.000   -1.41e+06    1.41e+06\n",
      "x9           -45.8304    3.3e+05     -0.000      1.000   -6.47e+05    6.47e+05\n",
      "x10           -1.4921   6.56e+05  -2.28e-06      1.000   -1.28e+06    1.28e+06\n",
      "x11           67.4157   5.63e+05      0.000      1.000    -1.1e+06     1.1e+06\n",
      "x12         -594.7342   6.15e+06  -9.67e-05      1.000   -1.21e+07    1.21e+07\n",
      "x13           73.4345   2.43e+06   3.02e-05      1.000   -4.77e+06    4.77e+06\n",
      "x14          583.7510   3.36e+06      0.000      1.000   -6.58e+06    6.58e+06\n",
      "x15            9.8635   1.95e+06   5.06e-06      1.000   -3.82e+06    3.82e+06\n",
      "x16          823.7858   2.78e+06      0.000      1.000   -5.44e+06    5.44e+06\n",
      "x17        -1537.9582   8.31e+06     -0.000      1.000   -1.63e+07    1.63e+07\n",
      "x18          -91.7780   1.26e+06  -7.27e-05      1.000   -2.47e+06    2.47e+06\n",
      "x19          -24.2143   5.25e+05  -4.61e-05      1.000   -1.03e+06    1.03e+06\n",
      "x20          -25.0234    2.9e+05  -8.61e-05      1.000   -5.69e+05    5.69e+05\n",
      "x21           -6.1072   1.06e+05  -5.77e-05      1.000   -2.07e+05    2.07e+05\n",
      "x22            8.0997    5.3e+05   1.53e-05      1.000   -1.04e+06    1.04e+06\n",
      "x23          -36.7637   7.86e+05  -4.68e-05      1.000   -1.54e+06    1.54e+06\n",
      "x24          -31.3588   2.84e+06  -1.11e-05      1.000   -5.56e+06    5.56e+06\n",
      "x25           28.1610   1.35e+05      0.000      1.000   -2.65e+05    2.65e+05\n",
      "x26            0.9275   2.38e+05    3.9e-06      1.000   -4.66e+05    4.66e+05\n",
      "x27          280.3538   1.18e+06      0.000      1.000   -2.31e+06    2.31e+06\n",
      "x28          -71.1846      3e+06  -2.37e-05      1.000   -5.88e+06    5.88e+06\n",
      "x29          210.5993   4.75e+06   4.44e-05      1.000    -9.3e+06     9.3e+06\n",
      "x30          -14.8851   1.93e+05  -7.69e-05      1.000   -3.79e+05    3.79e+05\n",
      "x31          453.4511   9.13e+06   4.97e-05      1.000   -1.79e+07    1.79e+07\n",
      "x32           46.7697   1.11e+05      0.000      1.000   -2.17e+05    2.18e+05\n",
      "x33           43.9814   2.44e+05      0.000      1.000   -4.79e+05    4.79e+05\n",
      "x34          -96.0496   7.07e+05     -0.000      1.000   -1.39e+06    1.39e+06\n",
      "x35           57.4053   1.35e+06   4.25e-05      1.000   -2.65e+06    2.65e+06\n",
      "x36           60.9702   4.11e+05      0.000      1.000   -8.06e+05    8.06e+05\n",
      "x37           37.7168   5.52e+05   6.84e-05      1.000   -1.08e+06    1.08e+06\n",
      "x38           37.0657   5.48e+05   6.77e-05      1.000   -1.07e+06    1.07e+06\n",
      "x39         -235.4865   3.73e+06  -6.32e-05      1.000    -7.3e+06     7.3e+06\n",
      "x40           -8.4258   1.93e+05  -4.37e-05      1.000   -3.78e+05    3.78e+05\n",
      "x41         -235.4863   3.73e+06  -6.32e-05      1.000    -7.3e+06     7.3e+06\n",
      "x42         1022.5266   5.48e+06      0.000      1.000   -1.07e+07    1.07e+07\n",
      "x43         1103.1855   2.98e+06      0.000      1.000   -5.83e+06    5.83e+06\n",
      "x44         -128.4063   4.97e+06  -2.59e-05      1.000   -9.73e+06    9.73e+06\n",
      "x45          382.0631   5.66e+06   6.76e-05      1.000   -1.11e+07    1.11e+07\n",
      "x46           98.2372   1.04e+06   9.45e-05      1.000   -2.04e+06    2.04e+06\n",
      "x47           10.5989   5.45e+05   1.94e-05      1.000   -1.07e+06    1.07e+06\n",
      "x48         -512.6371   1.32e+06     -0.000      1.000   -2.58e+06    2.58e+06\n",
      "x49        -4282.9479   2.03e+07     -0.000      1.000   -3.98e+07    3.98e+07\n",
      "x50          360.4767   1.53e+06      0.000      1.000      -3e+06       3e+06\n",
      "x51          360.5698   1.55e+06      0.000      1.000   -3.04e+06    3.04e+06\n",
      "x52          347.1215   1.41e+06      0.000      1.000   -2.77e+06    2.77e+06\n",
      "x53         4270.0479   1.92e+07      0.000      1.000   -3.77e+07    3.77e+07\n",
      "x54          199.0846    5.1e+06    3.9e-05      1.000      -1e+07       1e+07\n",
      "x55         -342.2869   9.22e+06  -3.71e-05      1.000   -1.81e+07    1.81e+07\n",
      "x56           18.2783   2.21e+06   8.26e-06      1.000   -4.34e+06    4.34e+06\n",
      "x57           69.4964   6.76e+05      0.000      1.000   -1.32e+06    1.32e+06\n",
      "x58          244.5550   2.48e+06   9.85e-05      1.000   -4.86e+06    4.87e+06\n",
      "x59          269.7477   2.43e+06      0.000      1.000   -4.77e+06    4.77e+06\n",
      "x60          550.7835   2.49e+06      0.000      1.000   -4.87e+06    4.88e+06\n",
      "x61         -311.6446   5.72e+06  -5.45e-05      1.000   -1.12e+07    1.12e+07\n",
      "x62          -21.5248   4.27e+05  -5.05e-05      1.000   -8.36e+05    8.36e+05\n",
      "x63          101.2506    2.3e+05      0.000      1.000   -4.51e+05    4.51e+05\n",
      "x64         -137.1958   6.82e+05     -0.000      1.000   -1.34e+06    1.34e+06\n",
      "x65           45.1700   7.75e+05   5.83e-05      1.000   -1.52e+06    1.52e+06\n",
      "x66         -125.5962    1.6e+06  -7.86e-05      1.000   -3.13e+06    3.13e+06\n",
      "x67           51.1876   6.63e+06   7.72e-06      1.000    -1.3e+07     1.3e+07\n",
      "x68           21.0661   7.82e+05   2.69e-05      1.000   -1.53e+06    1.53e+06\n",
      "x69         2426.2365   2.67e+08    9.1e-06      1.000   -5.23e+08    5.23e+08\n",
      "x70        -6925.8847    7.2e+08  -9.62e-06      1.000   -1.41e+09    1.41e+09\n",
      "x71         5635.7835   5.99e+08   9.41e-06      1.000   -1.17e+09    1.17e+09\n",
      "x72        -1115.1342   3.55e+08  -3.15e-06      1.000   -6.95e+08    6.95e+08\n",
      "x73         -302.0781   7.16e+07  -4.22e-06      1.000    -1.4e+08     1.4e+08\n",
      "x74         1353.2095   3.25e+08   4.16e-06      1.000   -6.37e+08    6.37e+08\n",
      "x75           23.4685   2.78e+05   8.44e-05      1.000   -5.45e+05    5.45e+05\n",
      "x76         -103.8302   5.11e+05     -0.000      1.000      -1e+06       1e+06\n",
      "x77           95.6318   5.49e+05      0.000      1.000   -1.08e+06    1.08e+06\n",
      "x78          -20.3846   1.61e+05     -0.000      1.000   -3.16e+05    3.16e+05\n",
      "x79           -8.7625   3.46e+05  -2.53e-05      1.000   -6.79e+05    6.79e+05\n",
      "x80           23.6596   5.74e+05   4.13e-05      1.000   -1.12e+06    1.12e+06\n",
      "x81           13.9540   5.81e+05    2.4e-05      1.000   -1.14e+06    1.14e+06\n",
      "x82          134.4487   1.43e+06   9.41e-05      1.000    -2.8e+06     2.8e+06\n",
      "x83          206.6953   9.84e+05      0.000      1.000   -1.93e+06    1.93e+06\n",
      "x84         -274.5695    1.2e+06     -0.000      1.000   -2.35e+06    2.34e+06\n",
      "x85          121.2581   5.23e+05      0.000      1.000   -1.02e+06    1.03e+06\n",
      "x86         -101.2853      4e+06  -2.53e-05      1.000   -7.83e+06    7.83e+06\n",
      "x87           16.1462    3.6e+06   4.48e-06      1.000   -7.06e+06    7.06e+06\n",
      "x88         -248.5614   7.81e+05     -0.000      1.000   -1.53e+06    1.53e+06\n",
      "x89          951.2599   4.42e+06      0.000      1.000   -8.65e+06    8.66e+06\n",
      "x90           -7.6245   2.78e+05  -2.75e-05      1.000   -5.44e+05    5.44e+05\n",
      "x91           84.4011   2.94e+06   2.87e-05      1.000   -5.76e+06    5.76e+06\n",
      "x92           46.7588   4.01e+05      0.000      1.000   -7.86e+05    7.86e+05\n",
      "x93           -5.9710   5.51e+05  -1.08e-05      1.000   -1.08e+06    1.08e+06\n",
      "x94        -1045.4023   8.62e+06     -0.000      1.000   -1.69e+07    1.69e+07\n",
      "x95          -89.5714   9.12e+05  -9.82e-05      1.000   -1.79e+06    1.79e+06\n",
      "x96            3.6832   1.08e+06   3.43e-06      1.000   -2.11e+06    2.11e+06\n",
      "x97         -114.2104   3.82e+06  -2.99e-05      1.000   -7.48e+06    7.48e+06\n",
      "x98           65.7040   8.97e+05   7.32e-05      1.000   -1.76e+06    1.76e+06\n",
      "x99        -2.804e+06   1.46e+10     -0.000      1.000   -2.86e+10    2.86e+10\n",
      "x100        2.804e+06   1.46e+10      0.000      1.000   -2.86e+10    2.86e+10\n",
      "x101           0.1605   3.98e+04   4.03e-06      1.000   -7.81e+04    7.81e+04\n",
      "x102         -42.5951   3.26e+05     -0.000      1.000   -6.39e+05    6.39e+05\n",
      "x103         -87.7805   6.33e+05     -0.000      1.000   -1.24e+06    1.24e+06\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "scaler = StandardScaler()\n",
    "# standardize the features (mean 0, variance 1)\n",
    "X = scaler.fit_transform(npsmall.copy())\n",
    "y = small_target.copy()\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results if this first model are bad. The low R2 and all P-values being 1 indicated that Logistic regerssion might not be a good fit for our data.\n",
    "\n",
    "There is a perfect spearation warning. This could be solved by using a different model (Firth logistic regression is usually recommended, but it's not part of the libraries I'm using). Another option would be to remove variables that are causing the bias. It difficult to figure out which variables are causing the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be two issues with the data that must be solved:\n",
    "1. The data is incredibly inbalanced. There are only a few distressed observations (8 out of 667). Doing some resampling (oversampling the distressed observations) might help. This can be achieved with SMOTE\n",
    "2. The data seems to have multicollinearity. I should try to remove features that have high correlations, and build a new model based on the reduced dataset. This can be achieved by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 659, 1.0: 8})\n",
      "Resampled dataset shape Counter({0.0: 659, 1.0: 659})\n"
     ]
    }
   ],
   "source": [
    "#resampling using SMOTE\n",
    "small_res, y_res = SMOTE().fit_resample(X, y)\n",
    "\n",
    "print(f\"Original dataset shape {Counter(y)}\")\n",
    "print(f\"Resampled dataset shape {Counter(y_res)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a 50/50 split in the data regarding distressed observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1218\n",
      "Model Family:                Binomial   Df Model:                           99\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       22105.\n",
      "Time:                        10:27:32   Pearson chi2:                 1.08e+18\n",
      "No. Iterations:                   100   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          -2.09e+15    1.2e+08  -1.74e+07      0.000   -2.09e+15   -2.09e+15\n",
      "x2         -3.035e+14   1.63e+07  -1.86e+07      0.000   -3.04e+14   -3.04e+14\n",
      "x3          6.196e+14   1.24e+08   4.98e+06      0.000     6.2e+14     6.2e+14\n",
      "x4          7.518e+14   2.01e+07   3.73e+07      0.000    7.52e+14    7.52e+14\n",
      "x5          1.244e+16   1.29e+08   9.65e+07      0.000    1.24e+16    1.24e+16\n",
      "x6          2.119e+15   5.13e+07   4.13e+07      0.000    2.12e+15    2.12e+15\n",
      "x7           2.41e+15   1.09e+08    2.2e+07      0.000    2.41e+15    2.41e+15\n",
      "x8         -4.469e+14   2.45e+07  -1.82e+07      0.000   -4.47e+14   -4.47e+14\n",
      "x9          1.358e+14   1.78e+07   7.62e+06      0.000    1.36e+14    1.36e+14\n",
      "x10         8.081e+13    1.6e+07   5.06e+06      0.000    8.08e+13    8.08e+13\n",
      "x11         5.087e+14   2.65e+07   1.92e+07      0.000    5.09e+14    5.09e+14\n",
      "x12         9.367e+15   2.21e+08   4.24e+07      0.000    9.37e+15    9.37e+15\n",
      "x13         5.707e+15      1e+08   5.69e+07      0.000    5.71e+15    5.71e+15\n",
      "x14         4.052e+15   1.28e+08   3.15e+07      0.000    4.05e+15    4.05e+15\n",
      "x15        -3.275e+15   1.45e+08  -2.26e+07      0.000   -3.28e+15   -3.28e+15\n",
      "x16           3.9e+15   1.13e+08   3.46e+07      0.000     3.9e+15     3.9e+15\n",
      "x17        -1.724e+15   4.59e+08  -3.75e+06      0.000   -1.72e+15   -1.72e+15\n",
      "x18         1.281e+15   2.11e+07   6.08e+07      0.000    1.28e+15    1.28e+15\n",
      "x19        -4.804e+13   1.37e+07   -3.5e+06      0.000    -4.8e+13    -4.8e+13\n",
      "x20          1.45e+14   9.43e+06   1.54e+07      0.000    1.45e+14    1.45e+14\n",
      "x21         3.235e+13   4.27e+06   7.57e+06      0.000    3.24e+13    3.24e+13\n",
      "x22         8.348e+14   1.54e+07   5.43e+07      0.000    8.35e+14    8.35e+14\n",
      "x23         7.567e+14   1.91e+07   3.95e+07      0.000    7.57e+14    7.57e+14\n",
      "x24        -2.534e+15   6.47e+07  -3.91e+07      0.000   -2.53e+15   -2.53e+15\n",
      "x25        -6.539e+13   5.19e+06  -1.26e+07      0.000   -6.54e+13   -6.54e+13\n",
      "x26         1.493e+14   7.82e+06   1.91e+07      0.000    1.49e+14    1.49e+14\n",
      "x27        -7.392e+14   3.25e+07  -2.27e+07      0.000   -7.39e+14   -7.39e+14\n",
      "x28         3.681e+15   9.49e+07   3.88e+07      0.000    3.68e+15    3.68e+15\n",
      "x29        -5.363e+14      1e+08  -5.35e+06      0.000   -5.36e+14   -5.36e+14\n",
      "x30        -4.209e+14   6.08e+06  -6.92e+07      0.000   -4.21e+14   -4.21e+14\n",
      "x31        -1.497e+15    1.8e+08  -8.31e+06      0.000    -1.5e+15    -1.5e+15\n",
      "x32         9.284e+14   7.65e+06   1.21e+08      0.000    9.28e+14    9.28e+14\n",
      "x33         4.478e+13   5.86e+06   7.64e+06      0.000    4.48e+13    4.48e+13\n",
      "x34        -7.012e+13   1.87e+07  -3.74e+06      0.000   -7.01e+13   -7.01e+13\n",
      "x35         1.857e+14   2.17e+07   8.57e+06      0.000    1.86e+14    1.86e+14\n",
      "x36        -3.585e+13   1.24e+07  -2.88e+06      0.000   -3.58e+13   -3.58e+13\n",
      "x37         1.108e+14   1.67e+07   6.62e+06      0.000    1.11e+14    1.11e+14\n",
      "x38         8.955e+13   1.66e+07    5.4e+06      0.000    8.95e+13    8.95e+13\n",
      "x39        -3.231e+15   1.95e+08  -1.66e+07      0.000   -3.23e+15   -3.23e+15\n",
      "x40        -4.771e+14   8.23e+06  -5.79e+07      0.000   -4.77e+14   -4.77e+14\n",
      "x41        -3.231e+15   1.95e+08  -1.66e+07      0.000   -3.23e+15   -3.23e+15\n",
      "x42        -4.986e+15   2.29e+08  -2.18e+07      0.000   -4.99e+15   -4.99e+15\n",
      "x43         1.219e+16   1.63e+08   7.47e+07      0.000    1.22e+16    1.22e+16\n",
      "x44        -2.297e+15    1.2e+08  -1.92e+07      0.000    -2.3e+15    -2.3e+15\n",
      "x45        -8.691e+14   2.04e+08  -4.26e+06      0.000   -8.69e+14   -8.69e+14\n",
      "x46         1.283e+15   5.14e+07    2.5e+07      0.000    1.28e+15    1.28e+15\n",
      "x47        -3.949e+14   1.77e+07  -2.23e+07      0.000   -3.95e+14   -3.95e+14\n",
      "x48         1.214e+15   3.56e+07   3.41e+07      0.000    1.21e+15    1.21e+15\n",
      "x49        -1.023e+15   1.94e+08  -5.28e+06      0.000   -1.02e+15   -1.02e+15\n",
      "x50         4.103e+14   1.28e+07    3.2e+07      0.000     4.1e+14     4.1e+14\n",
      "x51         2.487e+14   1.32e+07   1.88e+07      0.000    2.49e+14    2.49e+14\n",
      "x52         1.741e+14   1.35e+07   1.29e+07      0.000    1.74e+14    1.74e+14\n",
      "x53         3.295e+15    1.6e+08   2.06e+07      0.000    3.29e+15    3.29e+15\n",
      "x54         1.774e+15    1.8e+08   9.86e+06      0.000    1.77e+15    1.77e+15\n",
      "x55         3.154e+15   4.72e+08   6.68e+06      0.000    3.15e+15    3.15e+15\n",
      "x56         4.589e+14   5.54e+07   8.29e+06      0.000    4.59e+14    4.59e+14\n",
      "x57         7.973e+13   5.27e+07   1.51e+06      0.000    7.97e+13    7.97e+13\n",
      "x58        -1.253e+14    2.1e+08  -5.98e+05      0.000   -1.25e+14   -1.25e+14\n",
      "x59        -2.056e+14   2.02e+08  -1.02e+06      0.000   -2.06e+14   -2.06e+14\n",
      "x60        -7.903e+14    2.2e+08  -3.59e+06      0.000    -7.9e+14    -7.9e+14\n",
      "x61        -5.567e+14   2.37e+08  -2.35e+06      0.000   -5.57e+14   -5.57e+14\n",
      "x62        -2.914e+14   2.11e+07  -1.38e+07      0.000   -2.91e+14   -2.91e+14\n",
      "x63        -1.514e+14   1.74e+07  -8.68e+06      0.000   -1.51e+14   -1.51e+14\n",
      "x64         4.535e+14   1.53e+07   2.96e+07      0.000    4.53e+14    4.53e+14\n",
      "x65         5.577e+14   2.62e+07   2.13e+07      0.000    5.58e+14    5.58e+14\n",
      "x66        -1.587e+15   3.68e+07  -4.31e+07      0.000   -1.59e+15   -1.59e+15\n",
      "x67         4.721e+14   8.73e+07   5.41e+06      0.000    4.72e+14    4.72e+14\n",
      "x68        -1.228e+14   7.54e+06  -1.63e+07      0.000   -1.23e+14   -1.23e+14\n",
      "x69           3.2e+17   4.61e+09   6.94e+07      0.000     3.2e+17     3.2e+17\n",
      "x70        -8.785e+17   1.26e+10  -6.96e+07      0.000   -8.78e+17   -8.78e+17\n",
      "x71         7.314e+17   1.05e+10   6.97e+07      0.000    7.31e+17    7.31e+17\n",
      "x72        -3.183e+17   5.66e+09  -5.63e+07      0.000   -3.18e+17   -3.18e+17\n",
      "x73        -6.329e+16   1.17e+09   -5.4e+07      0.000   -6.33e+16   -6.33e+16\n",
      "x74         2.857e+17   5.29e+09    5.4e+07      0.000    2.86e+17    2.86e+17\n",
      "x75          1.06e+15   1.73e+07   6.12e+07      0.000    1.06e+15    1.06e+15\n",
      "x76        -1.965e+14   1.44e+07  -1.37e+07      0.000   -1.97e+14   -1.97e+14\n",
      "x77         1.588e+15   2.65e+07   5.99e+07      0.000    1.59e+15    1.59e+15\n",
      "x78         -2.09e+14   4.12e+06  -5.08e+07      0.000   -2.09e+14   -2.09e+14\n",
      "x79        -5.536e+14   1.55e+07  -3.58e+07      0.000   -5.54e+14   -5.54e+14\n",
      "x80         -8.14e+13   9.73e+06  -8.37e+06      0.000   -8.14e+13   -8.14e+13\n",
      "x81         2.112e+14   6.78e+06   3.11e+07      0.000    2.11e+14    2.11e+14\n",
      "x82        -1.512e+15   2.99e+07  -5.06e+07      0.000   -1.51e+15   -1.51e+15\n",
      "x83         8.903e+14   3.13e+07   2.85e+07      0.000     8.9e+14     8.9e+14\n",
      "x84         1.347e+13   4.56e+07   2.96e+05      0.000    1.35e+13    1.35e+13\n",
      "x85        -4.942e+14   2.28e+07  -2.17e+07      0.000   -4.94e+14   -4.94e+14\n",
      "x86         1.049e+15   7.01e+07    1.5e+07      0.000    1.05e+15    1.05e+15\n",
      "x87        -1.776e+14   6.37e+07  -2.79e+06      0.000   -1.78e+14   -1.78e+14\n",
      "x88         1.052e+15   4.21e+07    2.5e+07      0.000    1.05e+15    1.05e+15\n",
      "x89        -4.255e+15   1.23e+08  -3.47e+07      0.000   -4.26e+15   -4.26e+15\n",
      "x90        -4.113e+13   1.38e+07  -2.98e+06      0.000   -4.11e+13   -4.11e+13\n",
      "x91        -6.786e+14   4.55e+07  -1.49e+07      0.000   -6.79e+14   -6.79e+14\n",
      "x92        -3.586e+13   1.08e+07  -3.31e+06      0.000   -3.59e+13   -3.59e+13\n",
      "x93        -1.615e+15   2.27e+07   -7.1e+07      0.000   -1.62e+15   -1.62e+15\n",
      "x94         7.119e+15   1.25e+08    5.7e+07      0.000    7.12e+15    7.12e+15\n",
      "x95        -2.915e+14   4.58e+07  -6.36e+06      0.000   -2.92e+14   -2.92e+14\n",
      "x96        -4.938e+14   1.71e+07  -2.88e+07      0.000   -4.94e+14   -4.94e+14\n",
      "x97        -1.334e+15    7.8e+07  -1.71e+07      0.000   -1.33e+15   -1.33e+15\n",
      "x98         2.641e+14    4.9e+07    5.4e+06      0.000    2.64e+14    2.64e+14\n",
      "x99         1.026e+19   4.49e+11   2.29e+07      0.000    1.03e+19    1.03e+19\n",
      "x100       -1.026e+19   4.49e+11  -2.29e+07      0.000   -1.03e+19   -1.03e+19\n",
      "x101         8.56e+13   4.21e+06   2.03e+07      0.000    8.56e+13    8.56e+13\n",
      "x102       -4.367e+14   8.07e+06  -5.41e+07      0.000   -4.37e+14   -4.37e+14\n",
      "x103         2.56e+14   1.72e+07   1.49e+07      0.000    2.56e+14    2.56e+14\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "glm = sm.GLM(y_res, small_res, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply adding more distressed observations to the dataset didn't help with the model. The underlying issues with colinearity still should be present, even if there is no error regarding that anymore.\n",
    "\n",
    "To address that we can calculate the variance inflation factor (VIF) to find collinear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "minorityInterest                           inf\n",
       "totalLiabilitiesAndTotalEquity             inf\n",
       "totalEquity                                inf\n",
       "totalLiabilitiesAndStockholdersEquity      inf\n",
       "totalStockholdersEquity                    inf\n",
       "                                         ...  \n",
       "deferredRevenueNonCurrent                4.130\n",
       "weightedAverageShsOut                    2.924\n",
       "deferredRevenue                          2.786\n",
       "grossProfitRatio                         2.670\n",
       "distressed                               2.071\n",
       "Name: vif, Length: 103, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate a df with original features including the target variable\n",
    "vif_small = small.copy()\n",
    "vif_small['distressed'] = small_target.copy()\n",
    "\n",
    "# calculate VIF for each feature\n",
    "vals = [VIF(vif_small, i)\n",
    "        for i in range(1, vif_small.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals},\n",
    "                   index=vif_small.columns[1:])\n",
    "vif = vif.sort_values('vif', ascending=False)\n",
    "\n",
    "vif = vif['vif'].round(3)\n",
    "\n",
    "vif\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the VIF values, we can notice that some features end up with a VIF that converges into infinity. Those features can be removed from the dataset. (minorityInterest, totalLiabilitiesAndTotalEquity, totalEquity, totalLiabilitiesAndStockholdersEquity, totalStockholdersEquity, grossProfit, costOfRevenue, revenue)\n",
    "\n",
    "There are some features with very high VIFs, but for now we'll check those again, after the infinite VIFs have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the features with high VIF values\n",
    "toremove = ['minorityInterest', 'totalLiabilitiesAndTotalEquity', 'totalEquity',\n",
    "            'totalLiabilitiesAndStockholdersEquity', 'totalStockholdersEquity', 'grossProfit', 'costOfRevenue', 'revenue']\n",
    "\n",
    "for i in toremove:\n",
    "    if i in vif_small.columns:\n",
    "        vif_small.drop(columns=[i], inplace=True)\n",
    "    else:\n",
    "        print(f\"{i} not in columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eps                          3.621916e+10\n",
       "epsdiluted                   3.621858e+10\n",
       "cashAtEndOfPeriod            2.394800e+07\n",
       "cashAtBeginningOfPeriod      1.665048e+07\n",
       "operatingCashFlow            4.976434e+06\n",
       "                                 ...     \n",
       "deferredRevenueNonCurrent    3.891000e+00\n",
       "weightedAverageShsOut        2.924000e+00\n",
       "deferredRevenue              2.687000e+00\n",
       "grossProfitRatio             2.619000e+00\n",
       "distressed                   2.068000e+00\n",
       "Name: vif, Length: 95, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcualte VIFs again\n",
    "vals = [VIF(vif_small, i)\n",
    "        for i in range(1, vif_small.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals},\n",
    "                   index=vif_small.columns[1:])\n",
    "\n",
    "vif = vif.sort_values('vif', ascending=False)\n",
    "\n",
    "vif = vif['vif'].round(3)\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still very high VIF values, but let's try to create a model with those features removed, to see if there are improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1227\n",
      "Model Family:                Binomial   Df Model:                           90\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       460.52\n",
      "Time:                        10:27:45   Pearson chi2:                 2.25e+16\n",
      "No. Iterations:                    28   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================================\n",
      "                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "cashAndCashEquivalents                           2.865e+05      0.005   5.57e+07      0.000    2.86e+05    2.86e+05\n",
      "shortTermInvestments                             8.166e+04      0.001    6.7e+07      0.000    8.17e+04    8.17e+04\n",
      "cashAndShortTermInvestments                     -3.312e+05      0.005  -7.09e+07      0.000   -3.31e+05   -3.31e+05\n",
      "netReceivables                                  -6.864e+04      0.006  -1.24e+07      0.000   -6.86e+04   -6.86e+04\n",
      "inventory_balance_sheet                         -1.113e+05      0.002  -5.63e+07      0.000   -1.11e+05   -1.11e+05\n",
      "otherCurrentAssets                              -4.543e+04      0.002  -1.93e+07      0.000   -4.54e+04   -4.54e+04\n",
      "totalCurrentAssets                               3.901e+04      0.004   1.06e+07      0.000     3.9e+04     3.9e+04\n",
      "propertyPlantEquipmentNet                       -2.309e+05      0.004  -5.69e+07      0.000   -2.31e+05   -2.31e+05\n",
      "goodwill                                        -2.219e+05      0.004  -5.83e+07      0.000   -2.22e+05   -2.22e+05\n",
      "intangibleAssets                                 1.745e+05      0.004   4.72e+07      0.000    1.74e+05    1.74e+05\n",
      "goodwillAndIntangibleAssets                     -4.348e+04      0.003   -1.4e+07      0.000   -4.35e+04   -4.35e+04\n",
      "longTermInvestments                             -2.782e+05      0.003  -7.95e+07      0.000   -2.78e+05   -2.78e+05\n",
      "taxAssets                                        1.011e+04      0.002   5.56e+06      0.000    1.01e+04    1.01e+04\n",
      "otherNonCurrentAssets                            -279.7360      0.002   -1.8e+05      0.000    -279.739    -279.733\n",
      "totalNonCurrentAssets                           -9.467e+04      0.002  -6.19e+07      0.000   -9.47e+04   -9.47e+04\n",
      "otherAssets                                     -8.075e+04      0.002  -4.04e+07      0.000   -8.08e+04   -8.08e+04\n",
      "totalAssets                                      3.294e+04      0.002   1.48e+07      0.000    3.29e+04    3.29e+04\n",
      "accountPayables                                   1.36e+05      0.005   2.67e+07      0.000    1.36e+05    1.36e+05\n",
      "shortTermDebt                                    7.056e+04      0.004   1.73e+07      0.000    7.06e+04    7.06e+04\n",
      "taxPayables                                     -2.245e+05      0.012  -1.86e+07      0.000   -2.24e+05   -2.24e+05\n",
      "deferredRevenue                                 -2.306e+05      0.006  -3.76e+07      0.000   -2.31e+05   -2.31e+05\n",
      "otherCurrentLiabilities                          -5.18e+04      0.002  -3.08e+07      0.000   -5.18e+04   -5.18e+04\n",
      "totalCurrentLiabilities                          -1.35e+05      0.001  -9.09e+07      0.000   -1.35e+05   -1.35e+05\n",
      "longTermDebt                                    -4.564e+04      0.003  -1.47e+07      0.000   -4.56e+04   -4.56e+04\n",
      "deferredRevenueNonCurrent                        1.893e+04      0.001   2.53e+07      0.000    1.89e+04    1.89e+04\n",
      "deferredTaxLiabilitiesNonCurrent                -8.822e+04      0.008  -1.13e+07      0.000   -8.82e+04   -8.82e+04\n",
      "otherNonCurrentLiabilities                       8480.1677      0.000   1.93e+07      0.000    8480.167    8480.169\n",
      "totalNonCurrentLiabilities                      -7.564e+04      0.001  -7.07e+07      0.000   -7.56e+04   -7.56e+04\n",
      "otherLiabilities                                -3.676e+04      0.001  -3.75e+07      0.000   -3.68e+04   -3.68e+04\n",
      "capitalLeaseObligations                         -2.801e+04      0.008  -3.47e+06      0.000    -2.8e+04    -2.8e+04\n",
      "totalLiabilities                                 1.108e+05      0.001   8.15e+07      0.000    1.11e+05    1.11e+05\n",
      "preferredStock                                  -2.594e+05      0.005  -4.86e+07      0.000   -2.59e+05   -2.59e+05\n",
      "commonStock                                      1.852e+05      0.003   6.71e+07      0.000    1.85e+05    1.85e+05\n",
      "retainedEarnings                                -8.909e+04      0.001     -7e+07      0.000   -8.91e+04   -8.91e+04\n",
      "accumulatedOtherComprehensiveIncomeLoss         -5.662e+04      0.002  -3.72e+07      0.000   -5.66e+04   -5.66e+04\n",
      "othertotalStockholdersEquity                    -8.733e+04      0.001  -6.11e+07      0.000   -8.73e+04   -8.73e+04\n",
      "totalInvestments                                 2.225e+05      0.003   6.44e+07      0.000    2.22e+05    2.22e+05\n",
      "totalDebt                                       -9.354e+04      0.003  -2.83e+07      0.000   -9.35e+04   -9.35e+04\n",
      "netDebt                                          5.369e+04      0.003   1.58e+07      0.000    5.37e+04    5.37e+04\n",
      "netIncome_cash_flow_statement                    1.484e+06      0.034   4.33e+07      0.000    1.48e+06    1.48e+06\n",
      "depreciationAndAmortization_cash_flow_statement -2.037e+06      0.057  -3.58e+07      0.000   -2.04e+06   -2.04e+06\n",
      "deferredIncomeTax                                9.753e+05      0.034   2.83e+07      0.000    9.75e+05    9.75e+05\n",
      "stockBasedCompensation                           2.218e+05      0.032   7.01e+06      0.000    2.22e+05    2.22e+05\n",
      "changeInWorkingCapital                           7.355e+05      0.049    1.5e+07      0.000    7.35e+05    7.35e+05\n",
      "accountsReceivables                             -8.623e+05      0.040  -2.13e+07      0.000   -8.62e+05   -8.62e+05\n",
      "inventory_cash_flow_statement                   -7.966e+05      0.042   -1.9e+07      0.000   -7.97e+05   -7.97e+05\n",
      "accountsPayables                                -9.044e+05      0.045     -2e+07      0.000   -9.04e+05   -9.04e+05\n",
      "otherWorkingCapital                             -7.869e+05      0.041  -1.94e+07      0.000   -7.87e+05   -7.87e+05\n",
      "otherNonCashItems                                1.495e+05      0.030   4.98e+06      0.000    1.49e+05    1.49e+05\n",
      "netCashProvidedByOperatingActivities            -3.656e+06      0.100  -3.67e+07      0.000   -3.66e+06   -3.66e+06\n",
      "investmentsInPropertyPlantAndEquipment           1.279e+05      0.060   2.13e+06      0.000    1.28e+05    1.28e+05\n",
      "acquisitionsNet                                   1.11e+06      0.044   2.51e+07      0.000    1.11e+06    1.11e+06\n",
      "purchasesOfInvestments                           1.327e+06      0.043   3.08e+07      0.000    1.33e+06    1.33e+06\n",
      "salesMaturitiesOfInvestments                     1.355e+06      0.043   3.12e+07      0.000    1.36e+06    1.36e+06\n",
      "otherInvestingActivites                          1.743e+06      0.043    4.1e+07      0.000    1.74e+06    1.74e+06\n",
      "netCashUsedForInvestingActivites                -1.314e+06      0.046  -2.87e+07      0.000   -1.31e+06   -1.31e+06\n",
      "debtRepayment                                    4.997e+04      0.003   1.45e+07      0.000       5e+04       5e+04\n",
      "commonStockIssued                                9.474e+05      0.017   5.45e+07      0.000    9.47e+05    9.47e+05\n",
      "commonStockRepurchased                          -2.613e+05      0.011  -2.46e+07      0.000   -2.61e+05   -2.61e+05\n",
      "dividendsPaid                                   -3.785e+05      0.019  -1.96e+07      0.000   -3.79e+05   -3.79e+05\n",
      "otherFinancingActivites                            8.7e+04      0.006   1.56e+07      0.000     8.7e+04     8.7e+04\n",
      "netCashUsedProvidedByFinancingActivities        -7.501e+04      0.012  -6.23e+06      0.000    -7.5e+04    -7.5e+04\n",
      "effectOfForexChangesOnCash                      -3.496e+05      0.010  -3.67e+07      0.000    -3.5e+05    -3.5e+05\n",
      "netChangeInCash                                 -3.954e+06      0.639  -6.19e+06      0.000   -3.95e+06   -3.95e+06\n",
      "cashAtEndOfPeriod                                 4.05e+06      0.637   6.36e+06      0.000    4.05e+06    4.05e+06\n",
      "cashAtBeginningOfPeriod                         -4.191e+06      0.637  -6.58e+06      0.000   -4.19e+06   -4.19e+06\n",
      "operatingCashFlow                               -2.102e+07      1.199  -1.75e+07      0.000    -2.1e+07    -2.1e+07\n",
      "capitalExpenditure                              -2.473e+07      1.223  -2.02e+07      0.000   -2.47e+07   -2.47e+07\n",
      "freeCashFlow                                     2.486e+07      1.224   2.03e+07      0.000    2.49e+07    2.49e+07\n",
      "grossProfitRatio                                -5.203e+14    5.1e+06  -1.02e+08      0.000    -5.2e+14    -5.2e+14\n",
      "researchAndDevelopmentExpenses                   5.371e+05      0.013   3.98e+07      0.000    5.37e+05    5.37e+05\n",
      "generalAndAdministrativeExpenses                 2.477e+04      0.004   6.76e+06      0.000    2.48e+04    2.48e+04\n",
      "sellingAndMarketingExpenses                     -3.995e+04      0.003  -1.33e+07      0.000      -4e+04      -4e+04\n",
      "sellingGeneralAndAdministrativeExpenses           4.01e+05      0.006   7.27e+07      0.000    4.01e+05    4.01e+05\n",
      "otherExpenses                                    2.324e+05      0.004   5.55e+07      0.000    2.32e+05    2.32e+05\n",
      "operatingExpenses                               -1.865e+05      0.004   -4.6e+07      0.000   -1.86e+05   -1.86e+05\n",
      "costAndExpenses                                 -1.945e+04      0.001  -1.92e+07      0.000   -1.94e+04   -1.94e+04\n",
      "interestIncome                                  -1.259e+06      0.035  -3.65e+07      0.000   -1.26e+06   -1.26e+06\n",
      "interestExpense                                  4.688e+06      0.043   1.08e+08      0.000    4.69e+06    4.69e+06\n",
      "depreciationAndAmortization_income_statement     1.579e+06      0.041   3.81e+07      0.000    1.58e+06    1.58e+06\n",
      "ebitda                                           1.342e+05      0.019   7.08e+06      0.000    1.34e+05    1.34e+05\n",
      "ebitdaratio                                     -5.513e+14   1.28e+07  -4.29e+07      0.000   -5.51e+14   -5.51e+14\n",
      "operatingIncome                                  2.056e+05      0.007   3.07e+07      0.000    2.06e+05    2.06e+05\n",
      "operatingIncomeRatio                             1.327e+15   1.06e+07   1.25e+08      0.000    1.33e+15    1.33e+15\n",
      "totalOtherIncomeExpensesNet                      1.636e+05      0.005   3.17e+07      0.000    1.64e+05    1.64e+05\n",
      "incomeBeforeTax                                 -1.075e+06      0.021  -5.18e+07      0.000   -1.08e+06   -1.08e+06\n",
      "incomeBeforeTaxRatio                            -1.953e+15   4.28e+07  -4.56e+07      0.000   -1.95e+15   -1.95e+15\n",
      "incomeTaxExpense                                 6.394e+05      0.017   3.82e+07      0.000    6.39e+05    6.39e+05\n",
      "netIncome_income_statement                       -5.12e+05      0.013  -3.93e+07      0.000   -5.12e+05   -5.12e+05\n",
      "netIncomeRatio_income_statement                  1.607e+15   4.57e+07   3.52e+07      0.000    1.61e+15    1.61e+15\n",
      "eps                                             -9.025e+14   8.34e+06  -1.08e+08      0.000   -9.02e+14   -9.02e+14\n",
      "epsdiluted                                       9.025e+14   8.34e+06   1.08e+08      0.000    9.02e+14    9.02e+14\n",
      "weightedAverageShsOut                           -2.115e+05      0.007  -3.15e+07      0.000   -2.12e+05   -2.12e+05\n",
      "weightedAverageShsOutDil                          -2.2e+06      0.016  -1.39e+08      0.000    -2.2e+06    -2.2e+06\n",
      "marketcap                                       -9844.7780      0.000  -3.17e+07      0.000   -9844.779   -9844.777\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "#load and prepare dataset\n",
    "small2 = pd.read_csv('../datasets/1std_dataset.csv')\n",
    "small2.drop(columns=['z_score', 'year'], inplace=True)\n",
    "small2.drop(columns=toremove, inplace=True)\n",
    "\n",
    "#remove all non-numeric columns from the dataset\n",
    "numeric_columns = small2.select_dtypes(include=np.number).columns\n",
    "small2 = small2[numeric_columns]\n",
    "\n",
    "# create y, the target variable and X, the features\n",
    "X = small2.copy()\n",
    "X.drop(columns=['distressed'], inplace=True)\n",
    "y = small2.pop('distressed')\n",
    "\n",
    "# create dummy variables using smote\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# run the logistic regression model\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is still very bad, let's try to remove all features with a VIF higher than 10. This will remove most of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [VIF(X, i)\n",
    "        for i in range(1, X.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals},\n",
    "                   index=X.columns[1:])\n",
    "\n",
    "vif.where(vif['vif'] > 10, inplace=True)\n",
    "vif.dropna(inplace=True)\n",
    "vif = vif.sort_values('vif', ascending=False)\n",
    "\n",
    "toremove2 = list(vif.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1311\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       1149.4\n",
      "Time:                        10:27:50   Pearson chi2:                 9.94e+07\n",
      "No. Iterations:                   100   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "cashAndCashEquivalents       6.087e-11   5.26e-12     11.563      0.000    5.05e-11    7.12e-11\n",
      "deferredRevenue                2.1e-10   2.14e-10      0.981      0.327    -2.1e-10    6.29e-10\n",
      "deferredRevenueNonCurrent   -4.532e-11   2.74e-11     -1.655      0.098    -9.9e-11    8.37e-12\n",
      "preferredStock                 -0.0003      0.002     -0.159      0.873      -0.004       0.004\n",
      "commonStock                 -1.161e-11   4.15e-11     -0.280      0.780   -9.29e-11    6.97e-11\n",
      "grossProfitRatio               -1.1666      0.169     -6.887      0.000      -1.499      -0.835\n",
      "sellingAndMarketingExpenses -1.376e-09   3.53e-10     -3.896      0.000   -2.07e-09   -6.84e-10\n",
      "===============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "#load and prepare dataset\n",
    "small3 = pd.read_csv('../datasets/1std_dataset.csv')\n",
    "small3.drop(columns=['z_score', 'year'], inplace=True)\n",
    "small3.drop(columns=toremove, inplace=True)\n",
    "small3.drop(columns=toremove2, inplace=True)\n",
    "\n",
    "#remove all non-numeric columns from the dataset\n",
    "numeric_columns = small3.select_dtypes(include=np.number).columns\n",
    "small3 = small3[numeric_columns]\n",
    "\n",
    "# create y, the target variable and X, the features\n",
    "X = small3.copy()\n",
    "X.drop(columns=['distressed'], inplace=True)\n",
    "y = small3.pop('distressed')\n",
    "\n",
    "# create dummy variables using smote\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# run the logistic regression model\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have a resemblence of a regular model.\n",
    "We can standardize the data, and try to run the model again, this should give a better readable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1311\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -592.20\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       1184.4\n",
      "Time:                        10:27:50   Pearson chi2:                 5.94e+08\n",
      "No. Iterations:                    10   Pseudo R-squ. (CS):             0.3859\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             3.0221      0.248     12.189      0.000       2.536       3.508\n",
      "x2             0.1113      0.099      1.121      0.262      -0.083       0.306\n",
      "x3            -0.2601      0.132     -1.972      0.049      -0.519      -0.002\n",
      "x4            -7.2555      1.175     -6.173      0.000      -9.559      -4.952\n",
      "x5            -0.0103      0.056     -0.183      0.855      -0.121       0.100\n",
      "x6            -0.2483      0.076     -3.272      0.001      -0.397      -0.100\n",
      "x7            -1.5611      0.457     -3.414      0.001      -2.457      -0.665\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# standardize the features (mean 0, variance 1)\n",
    "X = scaler.fit_transform(X.copy())\n",
    "y = y.copy()\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 is 0.4 which is not that great. Considering how many features we dropped. I would suggest that logistic regression is simply not a good fit for the data we have at hand. But let's do some checks with the model, to get more insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43968821, 0.89784463, 0.3731107 , 0.45116236, 0.01835094,\n",
       "       0.02090706, 0.04089252, 0.0369803 , 0.40770469, 0.39706515])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do predictions\n",
    "probs = results.predict(X)\n",
    "probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels based on the predicted probabilities\n",
    "# 0 meaning not distressed, 1 meaning distressed, since that's how we trained the model\n",
    "# thresholf u is set to 0.5\n",
    "pred_labels = np.array(['0']*1318)\n",
    "pred_labels[probs>0.5] = '1'\n",
    "\n",
    "true_labels = y.round(decimals=0).astype(int).to_numpy().astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the confusion matrix. It might be a little confusing, since 0,1 seem to be reversed. That is because we're asking whether the company is distressed or not, so a 1 means 'yes, the company is distressed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        0    1\n",
       "Predicted          \n",
       "0          638  225\n",
       "1           21  434"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(pred_labels, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8133535660091047\n",
      "Missclassification rate: 0.18664643399089528\n",
      "Sensitivity: 0.9681335356600911\n",
      "Specificity: 0.6585735963581184\n"
     ]
    }
   ],
   "source": [
    "TP = 638\n",
    "FP = 225\n",
    "FN = 21\n",
    "TN = 434\n",
    "\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "missclassification_rate = (FP + FN) / (TP + FP + TN + FN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Missclassification rate: {missclassification_rate}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the confusion matrix are pretty good, but there's a good chance that this is due to overfitting. (We're testing the model on the data we trained it on).\n",
    "Specificity (true negative rate) is somewhat low, but this isn't a problem in our case. This simply means that companies, which are financially healthy get classified as distressed. Basically just being overly cautious. \n",
    "\n",
    "Let's create the ROC-curve to find the performance over the whole range of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<statsmodels.genmod.generalized_linear_model.GLMResultsWrapper object at 0x0000027B93EA3470> is not an estimator instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ROC curve\u001b[39;00m\n\u001b[0;32m      2\u001b[0m roc_curve \u001b[38;5;241m=\u001b[39m RocCurveDisplay\u001b[38;5;241m.\u001b[39mfrom_estimator\n\u001b[1;32m----> 4\u001b[0m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:299\u001b[0m, in \u001b[0;36mRocCurveDisplay.from_estimator\u001b[1;34m(cls, estimator, X, y, sample_weight, drop_intermediate, response_method, pos_label, name, ax, plot_chance_level, chance_level_kw, despine, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_estimator\u001b[39m(\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    210\u001b[0m ):\n\u001b[0;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a ROC Curve display from an estimator.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    >>> plt.show()\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 299\u001b[0m     y_pred, pos_label, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_predictions(\n\u001b[0;32m    309\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    310\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    320\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\sklearn\\utils\\_plotting.py:38\u001b[0m, in \u001b[0;36m_BinaryClassifierCurveDisplayMixin._validate_and_get_response_values\u001b[1;34m(cls, estimator, X, y, response_method, pos_label, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m check_matplotlib_support(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.from_estimator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m name \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[1;32m---> 38\u001b[0m y_pred, pos_label \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values_binary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, pos_label, name\n",
      "File \u001b[1;32mc:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\sklearn\\utils\\_response.py:298\u001b[0m, in \u001b[0;36m_get_response_values_binary\u001b[1;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the response values of a binary classifier.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.5\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    296\u001b[0m classification_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be a binary classifier.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 298\u001b[0m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_classifier(estimator):\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         classification_error \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1749\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1743\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1744\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m instance is not fitted yet. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate arguments before using this estimator.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1746\u001b[0m     )\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m get_tags(estimator)\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: <statsmodels.genmod.generalized_linear_model.GLMResultsWrapper object at 0x0000027B93EA3470> is not an estimator instance."
     ]
    }
   ],
   "source": [
    "# ROC curve\n",
    "roc_curve = RocCurveDisplay.from_estimator\n",
    "\n",
    "roc_curve(results, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
