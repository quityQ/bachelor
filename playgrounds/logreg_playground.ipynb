{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression, using scikit-learn and statsmodels (based on introduction to statistical learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from ISLP.models import summarize\n",
    "from ISLP import confusion_table\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "large = pd.read_csv('../datasets/full_cleaned_dataset.csv')\n",
    "small = pd.read_csv('../datasets/1std_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnesacary columns (z_score column, and index columns, and year))\n",
    "small.drop(columns=['z_score', 'year'], inplace=True)\n",
    "large.drop(columns=['Unnamed: 0', 'year'], inplace=True)\n",
    "\n",
    "#drop any non-numeric colums from both datasets\n",
    "#getting lists of numeric columns\n",
    "numeric_columns = large.select_dtypes(include=np.number).columns\n",
    "\n",
    "#dropping non-numeric columns from large and small datasets\n",
    "large = large[numeric_columns]\n",
    "small = small[numeric_columns]\n",
    "\n",
    "#move the target (distressed) out of the dataset\n",
    "large_target = large.pop('distressed')\n",
    "small_target = small.pop('distressed')\n",
    "\n",
    "#turn dfs in numpy arrays\n",
    "nplarge = large.to_numpy()\n",
    "npsmall = small.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                  667\n",
      "Model:                            GLM   Df Residuals:                      567\n",
      "Model Family:                Binomial   Df Model:                           99\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                   3.6244e-09\n",
      "Time:                        10:27:30   Pearson chi2:                 1.81e-09\n",
      "No. Iterations:                    30   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           326.1650   3.81e+06   8.57e-05      1.000   -7.46e+06    7.46e+06\n",
      "x2            63.7473    3.5e+05      0.000      1.000   -6.86e+05    6.86e+05\n",
      "x3          -903.6926   2.31e+06     -0.000      1.000   -4.52e+06    4.52e+06\n",
      "x4            86.0515   7.52e+05      0.000      1.000   -1.47e+06    1.47e+06\n",
      "x5           371.6054    5.6e+06   6.63e-05      1.000    -1.1e+07     1.1e+07\n",
      "x6            79.0391   1.07e+06   7.42e-05      1.000   -2.09e+06    2.09e+06\n",
      "x7           635.6358   2.89e+06      0.000      1.000   -5.67e+06    5.67e+06\n",
      "x8           -18.1822   7.18e+05  -2.53e-05      1.000   -1.41e+06    1.41e+06\n",
      "x9           -45.8304    3.3e+05     -0.000      1.000   -6.47e+05    6.47e+05\n",
      "x10           -1.4921   6.56e+05  -2.28e-06      1.000   -1.28e+06    1.28e+06\n",
      "x11           67.4157   5.63e+05      0.000      1.000    -1.1e+06     1.1e+06\n",
      "x12         -594.7342   6.15e+06  -9.67e-05      1.000   -1.21e+07    1.21e+07\n",
      "x13           73.4345   2.43e+06   3.02e-05      1.000   -4.77e+06    4.77e+06\n",
      "x14          583.7510   3.36e+06      0.000      1.000   -6.58e+06    6.58e+06\n",
      "x15            9.8635   1.95e+06   5.06e-06      1.000   -3.82e+06    3.82e+06\n",
      "x16          823.7858   2.78e+06      0.000      1.000   -5.44e+06    5.44e+06\n",
      "x17        -1537.9582   8.31e+06     -0.000      1.000   -1.63e+07    1.63e+07\n",
      "x18          -91.7780   1.26e+06  -7.27e-05      1.000   -2.47e+06    2.47e+06\n",
      "x19          -24.2143   5.25e+05  -4.61e-05      1.000   -1.03e+06    1.03e+06\n",
      "x20          -25.0234    2.9e+05  -8.61e-05      1.000   -5.69e+05    5.69e+05\n",
      "x21           -6.1072   1.06e+05  -5.77e-05      1.000   -2.07e+05    2.07e+05\n",
      "x22            8.0997    5.3e+05   1.53e-05      1.000   -1.04e+06    1.04e+06\n",
      "x23          -36.7637   7.86e+05  -4.68e-05      1.000   -1.54e+06    1.54e+06\n",
      "x24          -31.3588   2.84e+06  -1.11e-05      1.000   -5.56e+06    5.56e+06\n",
      "x25           28.1610   1.35e+05      0.000      1.000   -2.65e+05    2.65e+05\n",
      "x26            0.9275   2.38e+05    3.9e-06      1.000   -4.66e+05    4.66e+05\n",
      "x27          280.3538   1.18e+06      0.000      1.000   -2.31e+06    2.31e+06\n",
      "x28          -71.1846      3e+06  -2.37e-05      1.000   -5.88e+06    5.88e+06\n",
      "x29          210.5993   4.75e+06   4.44e-05      1.000    -9.3e+06     9.3e+06\n",
      "x30          -14.8851   1.93e+05  -7.69e-05      1.000   -3.79e+05    3.79e+05\n",
      "x31          453.4511   9.13e+06   4.97e-05      1.000   -1.79e+07    1.79e+07\n",
      "x32           46.7697   1.11e+05      0.000      1.000   -2.17e+05    2.18e+05\n",
      "x33           43.9814   2.44e+05      0.000      1.000   -4.79e+05    4.79e+05\n",
      "x34          -96.0496   7.07e+05     -0.000      1.000   -1.39e+06    1.39e+06\n",
      "x35           57.4053   1.35e+06   4.25e-05      1.000   -2.65e+06    2.65e+06\n",
      "x36           60.9702   4.11e+05      0.000      1.000   -8.06e+05    8.06e+05\n",
      "x37           37.7168   5.52e+05   6.84e-05      1.000   -1.08e+06    1.08e+06\n",
      "x38           37.0657   5.48e+05   6.77e-05      1.000   -1.07e+06    1.07e+06\n",
      "x39         -235.4865   3.73e+06  -6.32e-05      1.000    -7.3e+06     7.3e+06\n",
      "x40           -8.4258   1.93e+05  -4.37e-05      1.000   -3.78e+05    3.78e+05\n",
      "x41         -235.4863   3.73e+06  -6.32e-05      1.000    -7.3e+06     7.3e+06\n",
      "x42         1022.5266   5.48e+06      0.000      1.000   -1.07e+07    1.07e+07\n",
      "x43         1103.1855   2.98e+06      0.000      1.000   -5.83e+06    5.83e+06\n",
      "x44         -128.4063   4.97e+06  -2.59e-05      1.000   -9.73e+06    9.73e+06\n",
      "x45          382.0631   5.66e+06   6.76e-05      1.000   -1.11e+07    1.11e+07\n",
      "x46           98.2372   1.04e+06   9.45e-05      1.000   -2.04e+06    2.04e+06\n",
      "x47           10.5989   5.45e+05   1.94e-05      1.000   -1.07e+06    1.07e+06\n",
      "x48         -512.6371   1.32e+06     -0.000      1.000   -2.58e+06    2.58e+06\n",
      "x49        -4282.9479   2.03e+07     -0.000      1.000   -3.98e+07    3.98e+07\n",
      "x50          360.4767   1.53e+06      0.000      1.000      -3e+06       3e+06\n",
      "x51          360.5698   1.55e+06      0.000      1.000   -3.04e+06    3.04e+06\n",
      "x52          347.1215   1.41e+06      0.000      1.000   -2.77e+06    2.77e+06\n",
      "x53         4270.0479   1.92e+07      0.000      1.000   -3.77e+07    3.77e+07\n",
      "x54          199.0846    5.1e+06    3.9e-05      1.000      -1e+07       1e+07\n",
      "x55         -342.2869   9.22e+06  -3.71e-05      1.000   -1.81e+07    1.81e+07\n",
      "x56           18.2783   2.21e+06   8.26e-06      1.000   -4.34e+06    4.34e+06\n",
      "x57           69.4964   6.76e+05      0.000      1.000   -1.32e+06    1.32e+06\n",
      "x58          244.5550   2.48e+06   9.85e-05      1.000   -4.86e+06    4.87e+06\n",
      "x59          269.7477   2.43e+06      0.000      1.000   -4.77e+06    4.77e+06\n",
      "x60          550.7835   2.49e+06      0.000      1.000   -4.87e+06    4.88e+06\n",
      "x61         -311.6446   5.72e+06  -5.45e-05      1.000   -1.12e+07    1.12e+07\n",
      "x62          -21.5248   4.27e+05  -5.05e-05      1.000   -8.36e+05    8.36e+05\n",
      "x63          101.2506    2.3e+05      0.000      1.000   -4.51e+05    4.51e+05\n",
      "x64         -137.1958   6.82e+05     -0.000      1.000   -1.34e+06    1.34e+06\n",
      "x65           45.1700   7.75e+05   5.83e-05      1.000   -1.52e+06    1.52e+06\n",
      "x66         -125.5962    1.6e+06  -7.86e-05      1.000   -3.13e+06    3.13e+06\n",
      "x67           51.1876   6.63e+06   7.72e-06      1.000    -1.3e+07     1.3e+07\n",
      "x68           21.0661   7.82e+05   2.69e-05      1.000   -1.53e+06    1.53e+06\n",
      "x69         2426.2365   2.67e+08    9.1e-06      1.000   -5.23e+08    5.23e+08\n",
      "x70        -6925.8847    7.2e+08  -9.62e-06      1.000   -1.41e+09    1.41e+09\n",
      "x71         5635.7835   5.99e+08   9.41e-06      1.000   -1.17e+09    1.17e+09\n",
      "x72        -1115.1342   3.55e+08  -3.15e-06      1.000   -6.95e+08    6.95e+08\n",
      "x73         -302.0781   7.16e+07  -4.22e-06      1.000    -1.4e+08     1.4e+08\n",
      "x74         1353.2095   3.25e+08   4.16e-06      1.000   -6.37e+08    6.37e+08\n",
      "x75           23.4685   2.78e+05   8.44e-05      1.000   -5.45e+05    5.45e+05\n",
      "x76         -103.8302   5.11e+05     -0.000      1.000      -1e+06       1e+06\n",
      "x77           95.6318   5.49e+05      0.000      1.000   -1.08e+06    1.08e+06\n",
      "x78          -20.3846   1.61e+05     -0.000      1.000   -3.16e+05    3.16e+05\n",
      "x79           -8.7625   3.46e+05  -2.53e-05      1.000   -6.79e+05    6.79e+05\n",
      "x80           23.6596   5.74e+05   4.13e-05      1.000   -1.12e+06    1.12e+06\n",
      "x81           13.9540   5.81e+05    2.4e-05      1.000   -1.14e+06    1.14e+06\n",
      "x82          134.4487   1.43e+06   9.41e-05      1.000    -2.8e+06     2.8e+06\n",
      "x83          206.6953   9.84e+05      0.000      1.000   -1.93e+06    1.93e+06\n",
      "x84         -274.5695    1.2e+06     -0.000      1.000   -2.35e+06    2.34e+06\n",
      "x85          121.2581   5.23e+05      0.000      1.000   -1.02e+06    1.03e+06\n",
      "x86         -101.2853      4e+06  -2.53e-05      1.000   -7.83e+06    7.83e+06\n",
      "x87           16.1462    3.6e+06   4.48e-06      1.000   -7.06e+06    7.06e+06\n",
      "x88         -248.5614   7.81e+05     -0.000      1.000   -1.53e+06    1.53e+06\n",
      "x89          951.2599   4.42e+06      0.000      1.000   -8.65e+06    8.66e+06\n",
      "x90           -7.6245   2.78e+05  -2.75e-05      1.000   -5.44e+05    5.44e+05\n",
      "x91           84.4011   2.94e+06   2.87e-05      1.000   -5.76e+06    5.76e+06\n",
      "x92           46.7588   4.01e+05      0.000      1.000   -7.86e+05    7.86e+05\n",
      "x93           -5.9710   5.51e+05  -1.08e-05      1.000   -1.08e+06    1.08e+06\n",
      "x94        -1045.4023   8.62e+06     -0.000      1.000   -1.69e+07    1.69e+07\n",
      "x95          -89.5714   9.12e+05  -9.82e-05      1.000   -1.79e+06    1.79e+06\n",
      "x96            3.6832   1.08e+06   3.43e-06      1.000   -2.11e+06    2.11e+06\n",
      "x97         -114.2104   3.82e+06  -2.99e-05      1.000   -7.48e+06    7.48e+06\n",
      "x98           65.7040   8.97e+05   7.32e-05      1.000   -1.76e+06    1.76e+06\n",
      "x99        -2.804e+06   1.46e+10     -0.000      1.000   -2.86e+10    2.86e+10\n",
      "x100        2.804e+06   1.46e+10      0.000      1.000   -2.86e+10    2.86e+10\n",
      "x101           0.1605   3.98e+04   4.03e-06      1.000   -7.81e+04    7.81e+04\n",
      "x102         -42.5951   3.26e+05     -0.000      1.000   -6.39e+05    6.39e+05\n",
      "x103         -87.7805   6.33e+05     -0.000      1.000   -1.24e+06    1.24e+06\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "scaler = StandardScaler()\n",
    "# standardize the features (mean 0, variance 1)\n",
    "X = scaler.fit_transform(npsmall.copy())\n",
    "y = small_target.copy()\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results if this first model are bad. The low R2 and all P-values being 1 indicated that Logistic regerssion might not be a good fit for our data.\n",
    "\n",
    "There is a perfect spearation warning. This could be solved by using a different model (Firth logistic regression is usually recommended, but it's not part of the libraries I'm using). Another option would be to remove variables that are causing the bias. It difficult to figure out which variables are causing the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be two issues with the data that must be solved:\n",
    "1. The data is incredibly inbalanced. There are only a few distressed observations (8 out of 667). Doing some resampling (oversampling the distressed observations) might help. This can be achieved with SMOTE\n",
    "2. The data seems to have multicollinearity. I should try to remove features that have high correlations, and build a new model based on the reduced dataset. This can be achieved by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 659, 1.0: 8})\n",
      "Resampled dataset shape Counter({0.0: 659, 1.0: 659})\n"
     ]
    }
   ],
   "source": [
    "#resampling using SMOTE\n",
    "small_res, y_res = SMOTE().fit_resample(X, y)\n",
    "\n",
    "print(f\"Original dataset shape {Counter(y)}\")\n",
    "print(f\"Resampled dataset shape {Counter(y_res)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a 50/50 split in the data regarding distressed observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1218\n",
      "Model Family:                Binomial   Df Model:                           99\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       22105.\n",
      "Time:                        10:27:32   Pearson chi2:                 1.08e+18\n",
      "No. Iterations:                   100   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          -2.09e+15    1.2e+08  -1.74e+07      0.000   -2.09e+15   -2.09e+15\n",
      "x2         -3.035e+14   1.63e+07  -1.86e+07      0.000   -3.04e+14   -3.04e+14\n",
      "x3          6.196e+14   1.24e+08   4.98e+06      0.000     6.2e+14     6.2e+14\n",
      "x4          7.518e+14   2.01e+07   3.73e+07      0.000    7.52e+14    7.52e+14\n",
      "x5          1.244e+16   1.29e+08   9.65e+07      0.000    1.24e+16    1.24e+16\n",
      "x6          2.119e+15   5.13e+07   4.13e+07      0.000    2.12e+15    2.12e+15\n",
      "x7           2.41e+15   1.09e+08    2.2e+07      0.000    2.41e+15    2.41e+15\n",
      "x8         -4.469e+14   2.45e+07  -1.82e+07      0.000   -4.47e+14   -4.47e+14\n",
      "x9          1.358e+14   1.78e+07   7.62e+06      0.000    1.36e+14    1.36e+14\n",
      "x10         8.081e+13    1.6e+07   5.06e+06      0.000    8.08e+13    8.08e+13\n",
      "x11         5.087e+14   2.65e+07   1.92e+07      0.000    5.09e+14    5.09e+14\n",
      "x12         9.367e+15   2.21e+08   4.24e+07      0.000    9.37e+15    9.37e+15\n",
      "x13         5.707e+15      1e+08   5.69e+07      0.000    5.71e+15    5.71e+15\n",
      "x14         4.052e+15   1.28e+08   3.15e+07      0.000    4.05e+15    4.05e+15\n",
      "x15        -3.275e+15   1.45e+08  -2.26e+07      0.000   -3.28e+15   -3.28e+15\n",
      "x16           3.9e+15   1.13e+08   3.46e+07      0.000     3.9e+15     3.9e+15\n",
      "x17        -1.724e+15   4.59e+08  -3.75e+06      0.000   -1.72e+15   -1.72e+15\n",
      "x18         1.281e+15   2.11e+07   6.08e+07      0.000    1.28e+15    1.28e+15\n",
      "x19        -4.804e+13   1.37e+07   -3.5e+06      0.000    -4.8e+13    -4.8e+13\n",
      "x20          1.45e+14   9.43e+06   1.54e+07      0.000    1.45e+14    1.45e+14\n",
      "x21         3.235e+13   4.27e+06   7.57e+06      0.000    3.24e+13    3.24e+13\n",
      "x22         8.348e+14   1.54e+07   5.43e+07      0.000    8.35e+14    8.35e+14\n",
      "x23         7.567e+14   1.91e+07   3.95e+07      0.000    7.57e+14    7.57e+14\n",
      "x24        -2.534e+15   6.47e+07  -3.91e+07      0.000   -2.53e+15   -2.53e+15\n",
      "x25        -6.539e+13   5.19e+06  -1.26e+07      0.000   -6.54e+13   -6.54e+13\n",
      "x26         1.493e+14   7.82e+06   1.91e+07      0.000    1.49e+14    1.49e+14\n",
      "x27        -7.392e+14   3.25e+07  -2.27e+07      0.000   -7.39e+14   -7.39e+14\n",
      "x28         3.681e+15   9.49e+07   3.88e+07      0.000    3.68e+15    3.68e+15\n",
      "x29        -5.363e+14      1e+08  -5.35e+06      0.000   -5.36e+14   -5.36e+14\n",
      "x30        -4.209e+14   6.08e+06  -6.92e+07      0.000   -4.21e+14   -4.21e+14\n",
      "x31        -1.497e+15    1.8e+08  -8.31e+06      0.000    -1.5e+15    -1.5e+15\n",
      "x32         9.284e+14   7.65e+06   1.21e+08      0.000    9.28e+14    9.28e+14\n",
      "x33         4.478e+13   5.86e+06   7.64e+06      0.000    4.48e+13    4.48e+13\n",
      "x34        -7.012e+13   1.87e+07  -3.74e+06      0.000   -7.01e+13   -7.01e+13\n",
      "x35         1.857e+14   2.17e+07   8.57e+06      0.000    1.86e+14    1.86e+14\n",
      "x36        -3.585e+13   1.24e+07  -2.88e+06      0.000   -3.58e+13   -3.58e+13\n",
      "x37         1.108e+14   1.67e+07   6.62e+06      0.000    1.11e+14    1.11e+14\n",
      "x38         8.955e+13   1.66e+07    5.4e+06      0.000    8.95e+13    8.95e+13\n",
      "x39        -3.231e+15   1.95e+08  -1.66e+07      0.000   -3.23e+15   -3.23e+15\n",
      "x40        -4.771e+14   8.23e+06  -5.79e+07      0.000   -4.77e+14   -4.77e+14\n",
      "x41        -3.231e+15   1.95e+08  -1.66e+07      0.000   -3.23e+15   -3.23e+15\n",
      "x42        -4.986e+15   2.29e+08  -2.18e+07      0.000   -4.99e+15   -4.99e+15\n",
      "x43         1.219e+16   1.63e+08   7.47e+07      0.000    1.22e+16    1.22e+16\n",
      "x44        -2.297e+15    1.2e+08  -1.92e+07      0.000    -2.3e+15    -2.3e+15\n",
      "x45        -8.691e+14   2.04e+08  -4.26e+06      0.000   -8.69e+14   -8.69e+14\n",
      "x46         1.283e+15   5.14e+07    2.5e+07      0.000    1.28e+15    1.28e+15\n",
      "x47        -3.949e+14   1.77e+07  -2.23e+07      0.000   -3.95e+14   -3.95e+14\n",
      "x48         1.214e+15   3.56e+07   3.41e+07      0.000    1.21e+15    1.21e+15\n",
      "x49        -1.023e+15   1.94e+08  -5.28e+06      0.000   -1.02e+15   -1.02e+15\n",
      "x50         4.103e+14   1.28e+07    3.2e+07      0.000     4.1e+14     4.1e+14\n",
      "x51         2.487e+14   1.32e+07   1.88e+07      0.000    2.49e+14    2.49e+14\n",
      "x52         1.741e+14   1.35e+07   1.29e+07      0.000    1.74e+14    1.74e+14\n",
      "x53         3.295e+15    1.6e+08   2.06e+07      0.000    3.29e+15    3.29e+15\n",
      "x54         1.774e+15    1.8e+08   9.86e+06      0.000    1.77e+15    1.77e+15\n",
      "x55         3.154e+15   4.72e+08   6.68e+06      0.000    3.15e+15    3.15e+15\n",
      "x56         4.589e+14   5.54e+07   8.29e+06      0.000    4.59e+14    4.59e+14\n",
      "x57         7.973e+13   5.27e+07   1.51e+06      0.000    7.97e+13    7.97e+13\n",
      "x58        -1.253e+14    2.1e+08  -5.98e+05      0.000   -1.25e+14   -1.25e+14\n",
      "x59        -2.056e+14   2.02e+08  -1.02e+06      0.000   -2.06e+14   -2.06e+14\n",
      "x60        -7.903e+14    2.2e+08  -3.59e+06      0.000    -7.9e+14    -7.9e+14\n",
      "x61        -5.567e+14   2.37e+08  -2.35e+06      0.000   -5.57e+14   -5.57e+14\n",
      "x62        -2.914e+14   2.11e+07  -1.38e+07      0.000   -2.91e+14   -2.91e+14\n",
      "x63        -1.514e+14   1.74e+07  -8.68e+06      0.000   -1.51e+14   -1.51e+14\n",
      "x64         4.535e+14   1.53e+07   2.96e+07      0.000    4.53e+14    4.53e+14\n",
      "x65         5.577e+14   2.62e+07   2.13e+07      0.000    5.58e+14    5.58e+14\n",
      "x66        -1.587e+15   3.68e+07  -4.31e+07      0.000   -1.59e+15   -1.59e+15\n",
      "x67         4.721e+14   8.73e+07   5.41e+06      0.000    4.72e+14    4.72e+14\n",
      "x68        -1.228e+14   7.54e+06  -1.63e+07      0.000   -1.23e+14   -1.23e+14\n",
      "x69           3.2e+17   4.61e+09   6.94e+07      0.000     3.2e+17     3.2e+17\n",
      "x70        -8.785e+17   1.26e+10  -6.96e+07      0.000   -8.78e+17   -8.78e+17\n",
      "x71         7.314e+17   1.05e+10   6.97e+07      0.000    7.31e+17    7.31e+17\n",
      "x72        -3.183e+17   5.66e+09  -5.63e+07      0.000   -3.18e+17   -3.18e+17\n",
      "x73        -6.329e+16   1.17e+09   -5.4e+07      0.000   -6.33e+16   -6.33e+16\n",
      "x74         2.857e+17   5.29e+09    5.4e+07      0.000    2.86e+17    2.86e+17\n",
      "x75          1.06e+15   1.73e+07   6.12e+07      0.000    1.06e+15    1.06e+15\n",
      "x76        -1.965e+14   1.44e+07  -1.37e+07      0.000   -1.97e+14   -1.97e+14\n",
      "x77         1.588e+15   2.65e+07   5.99e+07      0.000    1.59e+15    1.59e+15\n",
      "x78         -2.09e+14   4.12e+06  -5.08e+07      0.000   -2.09e+14   -2.09e+14\n",
      "x79        -5.536e+14   1.55e+07  -3.58e+07      0.000   -5.54e+14   -5.54e+14\n",
      "x80         -8.14e+13   9.73e+06  -8.37e+06      0.000   -8.14e+13   -8.14e+13\n",
      "x81         2.112e+14   6.78e+06   3.11e+07      0.000    2.11e+14    2.11e+14\n",
      "x82        -1.512e+15   2.99e+07  -5.06e+07      0.000   -1.51e+15   -1.51e+15\n",
      "x83         8.903e+14   3.13e+07   2.85e+07      0.000     8.9e+14     8.9e+14\n",
      "x84         1.347e+13   4.56e+07   2.96e+05      0.000    1.35e+13    1.35e+13\n",
      "x85        -4.942e+14   2.28e+07  -2.17e+07      0.000   -4.94e+14   -4.94e+14\n",
      "x86         1.049e+15   7.01e+07    1.5e+07      0.000    1.05e+15    1.05e+15\n",
      "x87        -1.776e+14   6.37e+07  -2.79e+06      0.000   -1.78e+14   -1.78e+14\n",
      "x88         1.052e+15   4.21e+07    2.5e+07      0.000    1.05e+15    1.05e+15\n",
      "x89        -4.255e+15   1.23e+08  -3.47e+07      0.000   -4.26e+15   -4.26e+15\n",
      "x90        -4.113e+13   1.38e+07  -2.98e+06      0.000   -4.11e+13   -4.11e+13\n",
      "x91        -6.786e+14   4.55e+07  -1.49e+07      0.000   -6.79e+14   -6.79e+14\n",
      "x92        -3.586e+13   1.08e+07  -3.31e+06      0.000   -3.59e+13   -3.59e+13\n",
      "x93        -1.615e+15   2.27e+07   -7.1e+07      0.000   -1.62e+15   -1.62e+15\n",
      "x94         7.119e+15   1.25e+08    5.7e+07      0.000    7.12e+15    7.12e+15\n",
      "x95        -2.915e+14   4.58e+07  -6.36e+06      0.000   -2.92e+14   -2.92e+14\n",
      "x96        -4.938e+14   1.71e+07  -2.88e+07      0.000   -4.94e+14   -4.94e+14\n",
      "x97        -1.334e+15    7.8e+07  -1.71e+07      0.000   -1.33e+15   -1.33e+15\n",
      "x98         2.641e+14    4.9e+07    5.4e+06      0.000    2.64e+14    2.64e+14\n",
      "x99         1.026e+19   4.49e+11   2.29e+07      0.000    1.03e+19    1.03e+19\n",
      "x100       -1.026e+19   4.49e+11  -2.29e+07      0.000   -1.03e+19   -1.03e+19\n",
      "x101         8.56e+13   4.21e+06   2.03e+07      0.000    8.56e+13    8.56e+13\n",
      "x102       -4.367e+14   8.07e+06  -5.41e+07      0.000   -4.37e+14   -4.37e+14\n",
      "x103         2.56e+14   1.72e+07   1.49e+07      0.000    2.56e+14    2.56e+14\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "glm = sm.GLM(y_res, small_res, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply adding more distressed observations to the dataset didn't help with the model. The underlying issues with colinearity still should be present, even if there is no error regarding that anymore.\n",
    "\n",
    "To address that we can calculate the variance inflation factor (VIF) to find collinear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "minorityInterest                           inf\n",
       "totalLiabilitiesAndTotalEquity             inf\n",
       "totalEquity                                inf\n",
       "totalLiabilitiesAndStockholdersEquity      inf\n",
       "totalStockholdersEquity                    inf\n",
       "                                         ...  \n",
       "deferredRevenueNonCurrent                4.130\n",
       "weightedAverageShsOut                    2.924\n",
       "deferredRevenue                          2.786\n",
       "grossProfitRatio                         2.670\n",
       "distressed                               2.071\n",
       "Name: vif, Length: 103, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate a df with original features including the target variable\n",
    "vif_small = small.copy()\n",
    "vif_small['distressed'] = small_target.copy()\n",
    "\n",
    "# calculate VIF for each feature\n",
    "vals = [VIF(vif_small, i)\n",
    "        for i in range(1, vif_small.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals},\n",
    "                   index=vif_small.columns[1:])\n",
    "vif = vif.sort_values('vif', ascending=False)\n",
    "\n",
    "vif = vif['vif'].round(3)\n",
    "\n",
    "vif\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the VIF values, we can notice that some features end up with a VIF that converges into infinity. Those features can be removed from the dataset. (minorityInterest, totalLiabilitiesAndTotalEquity, totalEquity, totalLiabilitiesAndStockholdersEquity, totalStockholdersEquity, grossProfit, costOfRevenue, revenue)\n",
    "\n",
    "There are some features with very high VIFs, but for now we'll check those again, after the infinite VIFs have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the features with high VIF values\n",
    "toremove = ['minorityInterest', 'totalLiabilitiesAndTotalEquity', 'totalEquity',\n",
    "            'totalLiabilitiesAndStockholdersEquity', 'totalStockholdersEquity', 'grossProfit', 'costOfRevenue', 'revenue']\n",
    "\n",
    "for i in toremove:\n",
    "    if i in vif_small.columns:\n",
    "        vif_small.drop(columns=[i], inplace=True)\n",
    "    else:\n",
    "        print(f\"{i} not in columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eps                          3.621916e+10\n",
       "epsdiluted                   3.621858e+10\n",
       "cashAtEndOfPeriod            2.394800e+07\n",
       "cashAtBeginningOfPeriod      1.665048e+07\n",
       "operatingCashFlow            4.976434e+06\n",
       "                                 ...     \n",
       "deferredRevenueNonCurrent    3.891000e+00\n",
       "weightedAverageShsOut        2.924000e+00\n",
       "deferredRevenue              2.687000e+00\n",
       "grossProfitRatio             2.619000e+00\n",
       "distressed                   2.068000e+00\n",
       "Name: vif, Length: 95, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcualte VIFs again\n",
    "vals = [VIF(vif_small, i)\n",
    "        for i in range(1, vif_small.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals},\n",
    "                   index=vif_small.columns[1:])\n",
    "\n",
    "vif = vif.sort_values('vif', ascending=False)\n",
    "\n",
    "vif = vif['vif'].round(3)\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still very high VIF values, but let's try to create a model with those features removed, to see if there are improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1227\n",
      "Model Family:                Binomial   Df Model:                           90\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       460.52\n",
      "Time:                        10:27:45   Pearson chi2:                 2.25e+16\n",
      "No. Iterations:                    28   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================================\n",
      "                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "cashAndCashEquivalents                           2.865e+05      0.005   5.57e+07      0.000    2.86e+05    2.86e+05\n",
      "shortTermInvestments                             8.166e+04      0.001    6.7e+07      0.000    8.17e+04    8.17e+04\n",
      "cashAndShortTermInvestments                     -3.312e+05      0.005  -7.09e+07      0.000   -3.31e+05   -3.31e+05\n",
      "netReceivables                                  -6.864e+04      0.006  -1.24e+07      0.000   -6.86e+04   -6.86e+04\n",
      "inventory_balance_sheet                         -1.113e+05      0.002  -5.63e+07      0.000   -1.11e+05   -1.11e+05\n",
      "otherCurrentAssets                              -4.543e+04      0.002  -1.93e+07      0.000   -4.54e+04   -4.54e+04\n",
      "totalCurrentAssets                               3.901e+04      0.004   1.06e+07      0.000     3.9e+04     3.9e+04\n",
      "propertyPlantEquipmentNet                       -2.309e+05      0.004  -5.69e+07      0.000   -2.31e+05   -2.31e+05\n",
      "goodwill                                        -2.219e+05      0.004  -5.83e+07      0.000   -2.22e+05   -2.22e+05\n",
      "intangibleAssets                                 1.745e+05      0.004   4.72e+07      0.000    1.74e+05    1.74e+05\n",
      "goodwillAndIntangibleAssets                     -4.348e+04      0.003   -1.4e+07      0.000   -4.35e+04   -4.35e+04\n",
      "longTermInvestments                             -2.782e+05      0.003  -7.95e+07      0.000   -2.78e+05   -2.78e+05\n",
      "taxAssets                                        1.011e+04      0.002   5.56e+06      0.000    1.01e+04    1.01e+04\n",
      "otherNonCurrentAssets                            -279.7360      0.002   -1.8e+05      0.000    -279.739    -279.733\n",
      "totalNonCurrentAssets                           -9.467e+04      0.002  -6.19e+07      0.000   -9.47e+04   -9.47e+04\n",
      "otherAssets                                     -8.075e+04      0.002  -4.04e+07      0.000   -8.08e+04   -8.08e+04\n",
      "totalAssets                                      3.294e+04      0.002   1.48e+07      0.000    3.29e+04    3.29e+04\n",
      "accountPayables                                   1.36e+05      0.005   2.67e+07      0.000    1.36e+05    1.36e+05\n",
      "shortTermDebt                                    7.056e+04      0.004   1.73e+07      0.000    7.06e+04    7.06e+04\n",
      "taxPayables                                     -2.245e+05      0.012  -1.86e+07      0.000   -2.24e+05   -2.24e+05\n",
      "deferredRevenue                                 -2.306e+05      0.006  -3.76e+07      0.000   -2.31e+05   -2.31e+05\n",
      "otherCurrentLiabilities                          -5.18e+04      0.002  -3.08e+07      0.000   -5.18e+04   -5.18e+04\n",
      "totalCurrentLiabilities                          -1.35e+05      0.001  -9.09e+07      0.000   -1.35e+05   -1.35e+05\n",
      "longTermDebt                                    -4.564e+04      0.003  -1.47e+07      0.000   -4.56e+04   -4.56e+04\n",
      "deferredRevenueNonCurrent                        1.893e+04      0.001   2.53e+07      0.000    1.89e+04    1.89e+04\n",
      "deferredTaxLiabilitiesNonCurrent                -8.822e+04      0.008  -1.13e+07      0.000   -8.82e+04   -8.82e+04\n",
      "otherNonCurrentLiabilities                       8480.1677      0.000   1.93e+07      0.000    8480.167    8480.169\n",
      "totalNonCurrentLiabilities                      -7.564e+04      0.001  -7.07e+07      0.000   -7.56e+04   -7.56e+04\n",
      "otherLiabilities                                -3.676e+04      0.001  -3.75e+07      0.000   -3.68e+04   -3.68e+04\n",
      "capitalLeaseObligations                         -2.801e+04      0.008  -3.47e+06      0.000    -2.8e+04    -2.8e+04\n",
      "totalLiabilities                                 1.108e+05      0.001   8.15e+07      0.000    1.11e+05    1.11e+05\n",
      "preferredStock                                  -2.594e+05      0.005  -4.86e+07      0.000   -2.59e+05   -2.59e+05\n",
      "commonStock                                      1.852e+05      0.003   6.71e+07      0.000    1.85e+05    1.85e+05\n",
      "retainedEarnings                                -8.909e+04      0.001     -7e+07      0.000   -8.91e+04   -8.91e+04\n",
      "accumulatedOtherComprehensiveIncomeLoss         -5.662e+04      0.002  -3.72e+07      0.000   -5.66e+04   -5.66e+04\n",
      "othertotalStockholdersEquity                    -8.733e+04      0.001  -6.11e+07      0.000   -8.73e+04   -8.73e+04\n",
      "totalInvestments                                 2.225e+05      0.003   6.44e+07      0.000    2.22e+05    2.22e+05\n",
      "totalDebt                                       -9.354e+04      0.003  -2.83e+07      0.000   -9.35e+04   -9.35e+04\n",
      "netDebt                                          5.369e+04      0.003   1.58e+07      0.000    5.37e+04    5.37e+04\n",
      "netIncome_cash_flow_statement                    1.484e+06      0.034   4.33e+07      0.000    1.48e+06    1.48e+06\n",
      "depreciationAndAmortization_cash_flow_statement -2.037e+06      0.057  -3.58e+07      0.000   -2.04e+06   -2.04e+06\n",
      "deferredIncomeTax                                9.753e+05      0.034   2.83e+07      0.000    9.75e+05    9.75e+05\n",
      "stockBasedCompensation                           2.218e+05      0.032   7.01e+06      0.000    2.22e+05    2.22e+05\n",
      "changeInWorkingCapital                           7.355e+05      0.049    1.5e+07      0.000    7.35e+05    7.35e+05\n",
      "accountsReceivables                             -8.623e+05      0.040  -2.13e+07      0.000   -8.62e+05   -8.62e+05\n",
      "inventory_cash_flow_statement                   -7.966e+05      0.042   -1.9e+07      0.000   -7.97e+05   -7.97e+05\n",
      "accountsPayables                                -9.044e+05      0.045     -2e+07      0.000   -9.04e+05   -9.04e+05\n",
      "otherWorkingCapital                             -7.869e+05      0.041  -1.94e+07      0.000   -7.87e+05   -7.87e+05\n",
      "otherNonCashItems                                1.495e+05      0.030   4.98e+06      0.000    1.49e+05    1.49e+05\n",
      "netCashProvidedByOperatingActivities            -3.656e+06      0.100  -3.67e+07      0.000   -3.66e+06   -3.66e+06\n",
      "investmentsInPropertyPlantAndEquipment           1.279e+05      0.060   2.13e+06      0.000    1.28e+05    1.28e+05\n",
      "acquisitionsNet                                   1.11e+06      0.044   2.51e+07      0.000    1.11e+06    1.11e+06\n",
      "purchasesOfInvestments                           1.327e+06      0.043   3.08e+07      0.000    1.33e+06    1.33e+06\n",
      "salesMaturitiesOfInvestments                     1.355e+06      0.043   3.12e+07      0.000    1.36e+06    1.36e+06\n",
      "otherInvestingActivites                          1.743e+06      0.043    4.1e+07      0.000    1.74e+06    1.74e+06\n",
      "netCashUsedForInvestingActivites                -1.314e+06      0.046  -2.87e+07      0.000   -1.31e+06   -1.31e+06\n",
      "debtRepayment                                    4.997e+04      0.003   1.45e+07      0.000       5e+04       5e+04\n",
      "commonStockIssued                                9.474e+05      0.017   5.45e+07      0.000    9.47e+05    9.47e+05\n",
      "commonStockRepurchased                          -2.613e+05      0.011  -2.46e+07      0.000   -2.61e+05   -2.61e+05\n",
      "dividendsPaid                                   -3.785e+05      0.019  -1.96e+07      0.000   -3.79e+05   -3.79e+05\n",
      "otherFinancingActivites                            8.7e+04      0.006   1.56e+07      0.000     8.7e+04     8.7e+04\n",
      "netCashUsedProvidedByFinancingActivities        -7.501e+04      0.012  -6.23e+06      0.000    -7.5e+04    -7.5e+04\n",
      "effectOfForexChangesOnCash                      -3.496e+05      0.010  -3.67e+07      0.000    -3.5e+05    -3.5e+05\n",
      "netChangeInCash                                 -3.954e+06      0.639  -6.19e+06      0.000   -3.95e+06   -3.95e+06\n",
      "cashAtEndOfPeriod                                 4.05e+06      0.637   6.36e+06      0.000    4.05e+06    4.05e+06\n",
      "cashAtBeginningOfPeriod                         -4.191e+06      0.637  -6.58e+06      0.000   -4.19e+06   -4.19e+06\n",
      "operatingCashFlow                               -2.102e+07      1.199  -1.75e+07      0.000    -2.1e+07    -2.1e+07\n",
      "capitalExpenditure                              -2.473e+07      1.223  -2.02e+07      0.000   -2.47e+07   -2.47e+07\n",
      "freeCashFlow                                     2.486e+07      1.224   2.03e+07      0.000    2.49e+07    2.49e+07\n",
      "grossProfitRatio                                -5.203e+14    5.1e+06  -1.02e+08      0.000    -5.2e+14    -5.2e+14\n",
      "researchAndDevelopmentExpenses                   5.371e+05      0.013   3.98e+07      0.000    5.37e+05    5.37e+05\n",
      "generalAndAdministrativeExpenses                 2.477e+04      0.004   6.76e+06      0.000    2.48e+04    2.48e+04\n",
      "sellingAndMarketingExpenses                     -3.995e+04      0.003  -1.33e+07      0.000      -4e+04      -4e+04\n",
      "sellingGeneralAndAdministrativeExpenses           4.01e+05      0.006   7.27e+07      0.000    4.01e+05    4.01e+05\n",
      "otherExpenses                                    2.324e+05      0.004   5.55e+07      0.000    2.32e+05    2.32e+05\n",
      "operatingExpenses                               -1.865e+05      0.004   -4.6e+07      0.000   -1.86e+05   -1.86e+05\n",
      "costAndExpenses                                 -1.945e+04      0.001  -1.92e+07      0.000   -1.94e+04   -1.94e+04\n",
      "interestIncome                                  -1.259e+06      0.035  -3.65e+07      0.000   -1.26e+06   -1.26e+06\n",
      "interestExpense                                  4.688e+06      0.043   1.08e+08      0.000    4.69e+06    4.69e+06\n",
      "depreciationAndAmortization_income_statement     1.579e+06      0.041   3.81e+07      0.000    1.58e+06    1.58e+06\n",
      "ebitda                                           1.342e+05      0.019   7.08e+06      0.000    1.34e+05    1.34e+05\n",
      "ebitdaratio                                     -5.513e+14   1.28e+07  -4.29e+07      0.000   -5.51e+14   -5.51e+14\n",
      "operatingIncome                                  2.056e+05      0.007   3.07e+07      0.000    2.06e+05    2.06e+05\n",
      "operatingIncomeRatio                             1.327e+15   1.06e+07   1.25e+08      0.000    1.33e+15    1.33e+15\n",
      "totalOtherIncomeExpensesNet                      1.636e+05      0.005   3.17e+07      0.000    1.64e+05    1.64e+05\n",
      "incomeBeforeTax                                 -1.075e+06      0.021  -5.18e+07      0.000   -1.08e+06   -1.08e+06\n",
      "incomeBeforeTaxRatio                            -1.953e+15   4.28e+07  -4.56e+07      0.000   -1.95e+15   -1.95e+15\n",
      "incomeTaxExpense                                 6.394e+05      0.017   3.82e+07      0.000    6.39e+05    6.39e+05\n",
      "netIncome_income_statement                       -5.12e+05      0.013  -3.93e+07      0.000   -5.12e+05   -5.12e+05\n",
      "netIncomeRatio_income_statement                  1.607e+15   4.57e+07   3.52e+07      0.000    1.61e+15    1.61e+15\n",
      "eps                                             -9.025e+14   8.34e+06  -1.08e+08      0.000   -9.02e+14   -9.02e+14\n",
      "epsdiluted                                       9.025e+14   8.34e+06   1.08e+08      0.000    9.02e+14    9.02e+14\n",
      "weightedAverageShsOut                           -2.115e+05      0.007  -3.15e+07      0.000   -2.12e+05   -2.12e+05\n",
      "weightedAverageShsOutDil                          -2.2e+06      0.016  -1.39e+08      0.000    -2.2e+06    -2.2e+06\n",
      "marketcap                                       -9844.7780      0.000  -3.17e+07      0.000   -9844.779   -9844.777\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "#load and prepare dataset\n",
    "small2 = pd.read_csv('../datasets/1std_dataset.csv')\n",
    "small2.drop(columns=['z_score', 'year'], inplace=True)\n",
    "small2.drop(columns=toremove, inplace=True)\n",
    "\n",
    "#remove all non-numeric columns from the dataset\n",
    "numeric_columns = small2.select_dtypes(include=np.number).columns\n",
    "small2 = small2[numeric_columns]\n",
    "\n",
    "# create y, the target variable and X, the features\n",
    "X = small2.copy()\n",
    "X.drop(columns=['distressed'], inplace=True)\n",
    "y = small2.pop('distressed')\n",
    "\n",
    "# create dummy variables using smote\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# run the logistic regression model\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is still very bad, let's try to remove all features with a VIF higher than 10. This will remove most of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [VIF(X, i)\n",
    "        for i in range(1, X.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals},\n",
    "                   index=X.columns[1:])\n",
    "\n",
    "vif.where(vif['vif'] > 10, inplace=True)\n",
    "vif.dropna(inplace=True)\n",
    "vif = vif.sort_values('vif', ascending=False)\n",
    "\n",
    "toremove2 = list(vif.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1311\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       1149.4\n",
      "Time:                        10:27:50   Pearson chi2:                 9.94e+07\n",
      "No. Iterations:                   100   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "cashAndCashEquivalents       6.087e-11   5.26e-12     11.563      0.000    5.05e-11    7.12e-11\n",
      "deferredRevenue                2.1e-10   2.14e-10      0.981      0.327    -2.1e-10    6.29e-10\n",
      "deferredRevenueNonCurrent   -4.532e-11   2.74e-11     -1.655      0.098    -9.9e-11    8.37e-12\n",
      "preferredStock                 -0.0003      0.002     -0.159      0.873      -0.004       0.004\n",
      "commonStock                 -1.161e-11   4.15e-11     -0.280      0.780   -9.29e-11    6.97e-11\n",
      "grossProfitRatio               -1.1666      0.169     -6.887      0.000      -1.499      -0.835\n",
      "sellingAndMarketingExpenses -1.376e-09   3.53e-10     -3.896      0.000   -2.07e-09   -6.84e-10\n",
      "===============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\bicic\\Documents\\bachelor\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "#load and prepare dataset\n",
    "small3 = pd.read_csv('../datasets/1std_dataset.csv')\n",
    "small3.drop(columns=['z_score', 'year'], inplace=True)\n",
    "small3.drop(columns=toremove, inplace=True)\n",
    "small3.drop(columns=toremove2, inplace=True)\n",
    "\n",
    "#remove all non-numeric columns from the dataset\n",
    "numeric_columns = small3.select_dtypes(include=np.number).columns\n",
    "small3 = small3[numeric_columns]\n",
    "\n",
    "# create y, the target variable and X, the features\n",
    "X = small3.copy()\n",
    "X.drop(columns=['distressed'], inplace=True)\n",
    "y = small3.pop('distressed')\n",
    "\n",
    "# create dummy variables using smote\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# run the logistic regression model\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have a resemblence of a regular model.\n",
    "We can standardize the data, and try to run the model again, this should give a better readable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             distressed   No. Observations:                 1318\n",
      "Model:                            GLM   Df Residuals:                     1311\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -592.20\n",
      "Date:                Sat, 12 Apr 2025   Deviance:                       1184.4\n",
      "Time:                        10:27:50   Pearson chi2:                 5.94e+08\n",
      "No. Iterations:                    10   Pseudo R-squ. (CS):             0.3859\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             3.0221      0.248     12.189      0.000       2.536       3.508\n",
      "x2             0.1113      0.099      1.121      0.262      -0.083       0.306\n",
      "x3            -0.2601      0.132     -1.972      0.049      -0.519      -0.002\n",
      "x4            -7.2555      1.175     -6.173      0.000      -9.559      -4.952\n",
      "x5            -0.0103      0.056     -0.183      0.855      -0.121       0.100\n",
      "x6            -0.2483      0.076     -3.272      0.001      -0.397      -0.100\n",
      "x7            -1.5611      0.457     -3.414      0.001      -2.457      -0.665\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# standardize the features (mean 0, variance 1)\n",
    "X = scaler.fit_transform(X.copy())\n",
    "y = y.copy()\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 is 0.4 which is not that great. Considering how many features we dropped. I would suggest that logistic regression is simply not a good fit for the data we have at hand. But let's do some checks with the model, to get more insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43968821, 0.89784463, 0.3731107 , 0.45116236, 0.01835094,\n",
       "       0.02090706, 0.04089252, 0.0369803 , 0.40770469, 0.39706515])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do predictions\n",
    "probs = results.predict(X)\n",
    "probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels based on the predicted probabilities\n",
    "# 0 meaning not distressed, 1 meaning distressed, since that's how we trained the model\n",
    "# thresholf u is set to 0.5\n",
    "pred_labels = np.array(['0']*1318)\n",
    "pred_labels[probs>0.5] = '1'\n",
    "\n",
    "true_labels = y.round(decimals=0).astype(int).to_numpy().astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the confusion matrix. It might be a little confusing, since 0,1 seem to be reversed. That is because we're asking whether the company is distressed or not, so a 1 means 'yes, the company is distressed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        0    1\n",
       "Predicted          \n",
       "0          638  225\n",
       "1           21  434"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(pred_labels, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8133535660091047\n",
      "Missclassification rate: 0.18664643399089528\n",
      "Sensitivity: 0.9681335356600911\n",
      "Specificity: 0.6585735963581184\n"
     ]
    }
   ],
   "source": [
    "TP = 638\n",
    "FP = 225\n",
    "FN = 21\n",
    "TN = 434\n",
    "\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "missclassification_rate = (FP + FN) / (TP + FP + TN + FN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Missclassification rate: {missclassification_rate}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the confusion matrix are pretty good, but there's a good chance that this is due to overfitting. (We're testing the model on the data we trained it on).\n",
    "Specificity (true negative rate) is somewhat low, but this isn't a problem in our case. This simply means that companies, which are financially healthy get classified as distressed. Basically just being overly cautious. \n",
    "\n",
    "Let's create the ROC-curve to find the performance over the whole range of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x27b9a10d5b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "roc_curve = RocCurveDisplay.from_predictions\n",
    "\n",
    "roc_curve(true_labels, probs, pos_label='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AUC 0.87 implies good performance. But this still might be due to overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
